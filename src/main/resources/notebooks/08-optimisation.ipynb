{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b37be800-73ac-4f2f-8974-20fbe29fe302",
   "metadata": {},
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "from pyspark.sql import SparkSession, Window\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "# SparkSession is the entry point for the HIGH-LEVEL API (DataFrames, Spark SQL)\n",
    "spark = SparkSession. \\\n",
    "    builder. \\\n",
    "    config(\"spark.sql.autoBroadcastJoinThreshold\", 0). \\\n",
    "    appName(\"Joins\"). \\\n",
    "    master(\"local\"). \\\n",
    "    getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5780f42-8fd4-4976-97bd-24a2f6b0639f",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_df = spark.read. \\\n",
    "    format(\"json\"). \\\n",
    "    option(\"inferSchema\", \"true\"). \\\n",
    "    load(\"data/movies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "31bab786-9937-4492-8424-c96285e59e36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Window [row_number() windowspecdefinition(Title#20 ASC NULLS LAST, specifiedwindowframe(RowFrame, unboundedpreceding$(), currentrow$())) AS row_number() OVER (ORDER BY Title ASC NULLS LAST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)#124], [Title#20 ASC NULLS LAST]\n",
      "   +- Sort [Title#20 ASC NULLS LAST], false, 0\n",
      "      +- Exchange SinglePartition, ENSURE_REQUIREMENTS, [plan_id=157]\n",
      "         +- FileScan json [Title#20] Batched: false, DataFilters: [], Format: JSON, Location: InMemoryFileIndex(1 paths)[file:/D:/private/workspace/spark-cluster/src/main/resources/notebooks/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Title:string>\n",
      "\n",
      "\n",
      "+--------------------+--------------------------------------------------------------------------------------------------+\n",
      "|               Title|row_number() OVER (ORDER BY Title ASC NULLS LAST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)|\n",
      "+--------------------+--------------------------------------------------------------------------------------------------+\n",
      "|         10,000 B.C.|                                                                                                 1|\n",
      "|      102 Dalmatians|                                                                                                 2|\n",
      "|         10th & Wolf|                                                                                                 3|\n",
      "|               11:14|                                                                                                 4|\n",
      "|        12 Angry Men|                                                                                                 5|\n",
      "|           12 Rounds|                                                                                                 6|\n",
      "|      13 Going On 30|                                                                                                 7|\n",
      "|                1408|                                                                                                 8|\n",
      "|          15 Minutes|                                                                                                 9|\n",
      "|           16 Blocks|                                                                                                10|\n",
      "|          16 to Life|                                                                                                11|\n",
      "|                1776|                                                                                                12|\n",
      "|                1941|                                                                                                13|\n",
      "|    2 Fast 2 Furious|                                                                                                14|\n",
      "|     2 For the Money|                                                                                                15|\n",
      "|            20 Dates|                                                                                                16|\n",
      "|20,000 Leagues Un...|                                                                                                17|\n",
      "|20,000 Leagues Un...|                                                                                                18|\n",
      "|      200 Cigarettes|                                                                                                19|\n",
      "|2001: A Space Ody...|                                                                                                20|\n",
      "+--------------------+--------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1\n",
    "# what's wrong with a SinglePartition\n",
    "# how to add column with row_num() and count()\n",
    "# read.parquet.count use schema\n",
    "\n",
    "whole_dataset = Window.partitionBy().orderBy(col(\"Title\").asc_nulls_last())\n",
    "\n",
    "single_part_df = movies_df.select(col(\"Title\"), row_number().over(whole_dataset))\n",
    "#single_part_df = movies_df.select(col(\"Title\"))\\\n",
    "#    .withColumn(\"row_number\", monotonically_increasing_id())\n",
    "single_part_df.explain()\n",
    "single_part_df.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "970f09ac-1bf0-463d-a8af-a00b6d882ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [Title#20, monotonically_increasing_id() AS monotonically_increasing_id()#137L]\n",
      "+- FileScan json [Title#20] Batched: false, DataFilters: [], Format: JSON, Location: InMemoryFileIndex(1 paths)[file:/D:/private/workspace/spark-cluster/src/main/resources/notebooks/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<Title:string>\n",
      "\n",
      "\n",
      "+--------------------+--------------------------------------------------------------------------------------------------+\n",
      "|               Title|row_number() OVER (ORDER BY Title ASC NULLS LAST ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW)|\n",
      "+--------------------+--------------------------------------------------------------------------------------------------+\n",
      "|         10,000 B.C.|                                                                                                 1|\n",
      "|          16 to Life|                                                                                                11|\n",
      "|20,000 Leagues Un...|                                                                                                18|\n",
      "|   A Christmas Story|                                                                                                53|\n",
      "|  A Cinderella Story|                                                                                                54|\n",
      "|   A Dog of Flanders|                                                                                                56|\n",
      "|A Nightmare On El...|                                                                                                74|\n",
      "|    A Stir of Echoes|                                                                                                88|\n",
      "|           Adoration|                                                                                               106|\n",
      "|   Against the Ropes|                                                                                               109|\n",
      "|Alexander's Ragti...|                                                                                               125|\n",
      "| Along Came a Spider|                                                                                               144|\n",
      "|America's Sweethe...|                                                                                               150|\n",
      "|     American Beauty|                                                                                               151|\n",
      "|     American Dreamz|                                                                                               153|\n",
      "|             Amistad|                                                                                               164|\n",
      "|        Analyze That|                                                                                               176|\n",
      "|       Anything Else|                                                                                               194|\n",
      "|               Babel|                                                                                               237|\n",
      "|Back to the Futur...|                                                                                               245|\n",
      "+--------------------+--------------------------------------------------------------------------------------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "non_single_part_df = movies_df.select(col(\"Title\"), monotonically_increasing_id())\n",
    "non_single_part_df.explain()\n",
    "single_part_df.sample(0.1).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79e3fa1e-e087-44d5-94b2-db93bce29950",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: bigint]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2\n",
    "# How to read all data from cache?\n",
    "# Partial caching - cashing only parts which were calculated by some action. That is the couse that part of data\n",
    "# was from cache the other from source.\n",
    "\n",
    "partition_of_100_df = spark.range(0, 10000, 1, 100)\n",
    "partition_of_100_df.cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "149b6494-0e11-48dd-9ee7-baa64b5327f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+\n",
      "| id|\n",
      "+---+\n",
      "|  0|\n",
      "+---+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# use only one partition, use only one partition FRACTION CACHE 1% - http://localhost:4040/storage/\n",
    "# consistence can be uncorrected USE .count to put all data to cache\n",
    "# deserialized - as Java object, serialized - as Array[Byte]\n",
    "\n",
    "# partition_of_100_df.show(1)\n",
    "\n",
    "partition_of_100_df.count()\n",
    "partition_of_100_df.show(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eae1cc66-119e-4e53-a7c9-e4d381447d67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "InMemoryTableScan [id#150L]\n",
      "   +- InMemoryRelation [id#150L], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         +- *(1) Range (0, 10000, step=1, splits=100)\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# show data on local disk and disk spil\n",
    "# InMemoryRelation - load data to cache\n",
    "\n",
    "partition_of_100_df.explain()\n",
    "# InMemoryTableScn - load data to cache\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b0d254-563e-4d1f-882a-963c4a25df4b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "20ac63f2-633e-41a5-9c41-3e312c3b3d4d",
   "metadata": {},
   "source": [
    "# 4 Join optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7251e0e5-3274-46c0-8b24-16f9cced6380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataframe of facts\n",
    "\n",
    "crime_facts = spark \\\n",
    "    .read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"inferSchema\", \"true\") \\\n",
    "    .csv(\"data/crimes/crime.csv\")\n",
    "\n",
    "check = crime_facts.cache().count()\n",
    "assert(check != 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cde0c5f4-7309-4b62-b584-560ad4f39e84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Filter ('OFFENSE_CODE = 1402)\n",
      "+- Aggregate [OFFENSE_CODE#246], [OFFENSE_CODE#246, count(1) AS count#846L]\n",
      "   +- Relation [INCIDENT_NUMBER#245,OFFENSE_CODE#246,OFFENSE_CODE_GROUP#247,OFFENSE_DESCRIPTION#248,DISTRICT#249,REPORTING_AREA#250,SHOOTING#251,OCCURRED_ON_DATE#252,YEAR#253,MONTH#254,DAY_OF_WEEK#255,HOUR#256,UCR_PART#257,STREET#258,Lat#259,Long#260,Location#261] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "OFFENSE_CODE: int, count: bigint\n",
      "Filter (OFFENSE_CODE#246 = 1402)\n",
      "+- Aggregate [OFFENSE_CODE#246], [OFFENSE_CODE#246, count(1) AS count#846L]\n",
      "   +- Relation [INCIDENT_NUMBER#245,OFFENSE_CODE#246,OFFENSE_CODE_GROUP#247,OFFENSE_DESCRIPTION#248,DISTRICT#249,REPORTING_AREA#250,SHOOTING#251,OCCURRED_ON_DATE#252,YEAR#253,MONTH#254,DAY_OF_WEEK#255,HOUR#256,UCR_PART#257,STREET#258,Lat#259,Long#260,Location#261] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [OFFENSE_CODE#246], [OFFENSE_CODE#246, count(1) AS count#846L]\n",
      "+- Project [OFFENSE_CODE#246]\n",
      "   +- Filter (isnotnull(OFFENSE_CODE#246) AND (OFFENSE_CODE#246 = 1402))\n",
      "      +- InMemoryRelation [INCIDENT_NUMBER#245, OFFENSE_CODE#246, OFFENSE_CODE_GROUP#247, OFFENSE_DESCRIPTION#248, DISTRICT#249, REPORTING_AREA#250, SHOOTING#251, OCCURRED_ON_DATE#252, YEAR#253, MONTH#254, DAY_OF_WEEK#255, HOUR#256, UCR_PART#257, STREET#258, Lat#259, Long#260, Location#261], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "            +- FileScan csv [INCIDENT_NUMBER#245,OFFENSE_CODE#246,OFFENSE_CODE_GROUP#247,OFFENSE_DESCRIPTION#248,DISTRICT#249,REPORTING_AREA#250,SHOOTING#251,OCCURRED_ON_DATE#252,YEAR#253,MONTH#254,DAY_OF_WEEK#255,HOUR#256,UCR_PART#257,STREET#258,Lat#259,Long#260,Location#261] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/D:/private/workspace/spark-cluster/src/main/resources/notebooks/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<INCIDENT_NUMBER:string,OFFENSE_CODE:int,OFFENSE_CODE_GROUP:string,OFFENSE_DESCRIPTION:stri...\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- HashAggregate(keys=[OFFENSE_CODE#246], functions=[count(1)], output=[OFFENSE_CODE#246, count#846L])\n",
      "   +- Exchange hashpartitioning(OFFENSE_CODE#246, 200), ENSURE_REQUIREMENTS, [plan_id=372]\n",
      "      +- HashAggregate(keys=[OFFENSE_CODE#246], functions=[partial_count(1)], output=[OFFENSE_CODE#246, count#1106L])\n",
      "         +- Filter (isnotnull(OFFENSE_CODE#246) AND (OFFENSE_CODE#246 = 1402))\n",
      "            +- InMemoryTableScan [OFFENSE_CODE#246], [isnotnull(OFFENSE_CODE#246), (OFFENSE_CODE#246 = 1402)]\n",
      "                  +- InMemoryRelation [INCIDENT_NUMBER#245, OFFENSE_CODE#246, OFFENSE_CODE_GROUP#247, OFFENSE_DESCRIPTION#248, DISTRICT#249, REPORTING_AREA#250, SHOOTING#251, OCCURRED_ON_DATE#252, YEAR#253, MONTH#254, DAY_OF_WEEK#255, HOUR#256, UCR_PART#257, STREET#258, Lat#259, Long#260, Location#261], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                        +- FileScan csv [INCIDENT_NUMBER#245,OFFENSE_CODE#246,OFFENSE_CODE_GROUP#247,OFFENSE_DESCRIPTION#248,DISTRICT#249,REPORTING_AREA#250,SHOOTING#251,OCCURRED_ON_DATE#252,YEAR#253,MONTH#254,DAY_OF_WEEK#255,HOUR#256,UCR_PART#257,STREET#258,Lat#259,Long#260,Location#261] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/D:/private/workspace/spark-cluster/src/main/resources/notebooks/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<INCIDENT_NUMBER:string,OFFENSE_CODE:int,OFFENSE_CODE_GROUP:string,OFFENSE_DESCRIPTION:stri...\n",
      "\n",
      "+------------+-----+\n",
      "|OFFENSE_CODE|count|\n",
      "+------------+-----+\n",
      "|        1402|   67|\n",
      "+------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Catalyst optimiser - move filter up\n",
    "\n",
    "grouped_crime_df = crime_facts.\\\n",
    "    groupBy(col(\"OFFENSE_CODE\")).\\\n",
    "    count().\\\n",
    "    filter(col(\"OFFENSE_CODE\") == 1402)\n",
    "\n",
    "grouped_crime_df.explain(True)\n",
    "grouped_crime_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c518f26c-a519-4491-b78a-7eb7cc833f4d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+----------------------------------------------------------+\n",
      "|CODE|NAME                                                      |\n",
      "+----+----------------------------------------------------------+\n",
      "|612 |LARCENY PURSE SNATCH - NO FORCE                           |\n",
      "|613 |LARCENY SHOPLIFTING                                       |\n",
      "|615 |LARCENY THEFT OF MV PARTS & ACCESSORIES                   |\n",
      "|1731|INCEST                                                    |\n",
      "|3111|LICENSE PREMISE VIOLATION                                 |\n",
      "|2646|LIQUOR - DRINKING IN PUBLIC                               |\n",
      "|2204|LIQUOR LAW VIOLATION                                      |\n",
      "|3810|M/V ACCIDENT - INVOLVING �BICYCLE - INJURY                |\n",
      "|3801|M/V ACCIDENT - OTHER                                      |\n",
      "|3807|M/V ACCIDENT - OTHER CITY VEHICLE                         |\n",
      "|3803|M/V ACCIDENT - PERSONAL INJURY                            |\n",
      "|3805|M/V ACCIDENT - POLICE VEHICLE                             |\n",
      "|3802|M/V ACCIDENT - PROPERTY �DAMAGE                           |\n",
      "|3205|M/V PLATES - LOST                                         |\n",
      "|123 |MANSLAUGHTER - NON-VEHICLE - NEGLIGENCE                   |\n",
      "|121 |MANSLAUGHTER - VEHICLE - NEGLIGENCE                       |\n",
      "|3501|MISSING PERSON                                            |\n",
      "|3502|MISSING PERSON - LOCATED                                  |\n",
      "|3503|MISSING PERSON - NOT REPORTED - LOCATED                   |\n",
      "|111 |MURDER, NON-NEGLIGIENT MANSLAUGHTER                       |\n",
      "|3303|NOISY PARTY/RADIO-ARREST                                  |\n",
      "|2623|OBSCENE MATERIALS - PORNOGRAPHY                           |\n",
      "|2628|OBSCENE PHONE CALLS                                       |\n",
      "|1711|OPEN & GROSS LEWDNESS                                     |\n",
      "|2007|VIOL. OF RESTRAINING ORDER W NO ARREST                    |\n",
      "|2102|OPERATING UNDER THE INFLUENCE DRUGS                       |\n",
      "|2660|OTHER OFFENSE                                             |\n",
      "|2900|VAL - VIOLATION OF AUTO LAW - OTHER                       |\n",
      "|1109|FRAUD - WIRE                                              |\n",
      "|2616|POSSESSION OF BURGLARIOUS TOOLS                           |\n",
      "|2606|PRISONER ATTEMPT TO RESCUE                                |\n",
      "|2636|PRISONER ESCAPE / ESCAPE & RECAPTURE                      |\n",
      "|3029|PRISONER - SUICIDE / SUICIDE ATTEMPT                      |\n",
      "|3106|PROPERTY - ACCIDENTAL DAMAGE                              |\n",
      "|1300|STOLEN PROPERTY - BUYING / RECEIVING / POSSESSING         |\n",
      "|3207|PROPERTY - FOUND                                          |\n",
      "|3201|PROPERTY - LOST                                           |\n",
      "|3202|PROPERTY - LOST THEN LOCATED                              |\n",
      "|3208|PROPERTY - MISSING                                        |\n",
      "|1304|PROPERTY - STOLEN THEN RECOVERED                          |\n",
      "|1603|PROSTITUTION - ASSISTING OR PROMOTING                     |\n",
      "|1605|PROSTITUTION - COMMON NIGHTWALKER                         |\n",
      "|1601|PROSTITUTION                                              |\n",
      "|1602|PROSTITUTION - SOLICITING                                 |\n",
      "|242 |RAPE - ATTEMPT - SODOMY                                   |\n",
      "|254 |RAPE - COMPLETE - FONDLING                                |\n",
      "|271 |RAPE - COMPLETE - OTHER                                   |\n",
      "|244 |RAPE - ATTEMPT - FONDLING                                 |\n",
      "|251 |RAPE - COMPLETE - FORCIBLE                                |\n",
      "|241 |RAPE - ATTEMPT - FORCIBLE                                 |\n",
      "|243 |RAPE - ATTEMPT - SEXUAL ASSAULT W/ OBJECT                 |\n",
      "|261 |RAPE - ATTEMPT - OTHER                                    |\n",
      "|252 |RAPE - COMPLETE - SODOMY                                  |\n",
      "|253 |RAPE - COMPLETE - SEXUAL ASSAULT W/ OBJECT                |\n",
      "|735 |RECOVERED - MV RECOVERED IN BOSTON (STOLEN OUTSIDE BOSTON)|\n",
      "|3620|REPORT AFFECTING OTHER DEPTS.                             |\n",
      "|301 |ROBBERY - STREET                                          |\n",
      "|311 |ROBBERY - COMMERCIAL                                      |\n",
      "|351 |ROBBERY - BANK                                            |\n",
      "|361 |ROBBERY - OTHER                                           |\n",
      "|371 |ROBBERY - HOME INVASION                                   |\n",
      "|381 |ROBBERY - CAR JACKING                                     |\n",
      "|3403|PROTECTIVE CUSTODY / SAFEKEEPING                          |\n",
      "|3109|SERVICE TO OTHER PD INSIDE OF MA.                         |\n",
      "|3110|SERVICE TO OTHER PD OUTSIDE OF MA.                        |\n",
      "|1730|SEXUAL ASSAULT INVESTIGATION                              |\n",
      "|3006|SICK/INJURED/MEDICAL - PERSON                             |\n",
      "|801 |ASSAULT - SIMPLE                                          |\n",
      "|804 |STALKING                                                  |\n",
      "|1704|STATUTORY RAPE                                            |\n",
      "|2647|THREATS TO DO BODILY HARM                                 |\n",
      "|3410|TOWED MOTOR VEHICLE                                       |\n",
      "|2610|TRESPASSING                                               |\n",
      "|2642|TRUANCY / RUNAWAY                                         |\n",
      "|2915|VAL - MISCELLANEOUS                                       |\n",
      "|2907|VAL - OPERATING AFTER REV/SUSP.                           |\n",
      "|2906|VAL - OPERATING UNREG/UNINS �CAR                          |\n",
      "|2905|VAL - OPERATING WITHOUT LICENSE                           |\n",
      "|2914|VAL - OPERATING W/O AUTHORIZATION LAWFUL                  |\n",
      "|1402|VANDALISM                                                 |\n",
      "|1415|GRAFFITI                                                  |\n",
      "|3301|VERBAL DISPUTE                                            |\n",
      "|2657|VIOLATION - CITY ORDINANCE                                |\n",
      "|2641|VIOLATION - HAWKER AND PEDDLER                            |\n",
      "|2006|VIOL. OF RESTRAINING ORDER W ARREST                       |\n",
      "|2663|VIOLATION - CITY ORDINANCE CONSTRUCTION PERMIT            |\n",
      "|3125|WARRANT ARREST                                            |\n",
      "|2511|KIDNAPPING - ENTICING OR ATTEMPTED                        |\n",
      "|2613|ANIMAL ABUSE                                              |\n",
      "|3002|ANIMAL CONTROL - DOG BITES - ETC.                         |\n",
      "|3402|ANIMAL INCIDENTS                                          |\n",
      "|802 |ASSAULT SIMPLE - BATTERY                                  |\n",
      "|423 |ASSAULT - AGGRAVATED                                      |\n",
      "|413 |ASSAULT - AGGRAVATED - BATTERY                            |\n",
      "|724 |AUTO THEFT                                                |\n",
      "|727 |AUTO THEFT - LEASED/RENTED VEHICLE                        |\n",
      "|706 |AUTO THEFT - MOTORCYCLE / SCOOTER                         |\n",
      "|541 |BURGLARY - COMMERICAL - ATTEMPT                           |\n",
      "|540 |BURGLARY - COMMERICAL - FORCE                             |\n",
      "|562 |BURGLARY - OTHER - NO FORCE                               |\n",
      "+----+----------------------------------------------------------+\n",
      "only showing top 100 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# small table with dict data\n",
    "offense_сodes = spark.\\\n",
    "    read.\\\n",
    "    option(\"header\", \"true\").\\\n",
    "    option(\"inferSchema\", \"true\").\\\n",
    "    csv(\"data/crimes/offense_codes.csv\")\n",
    "\n",
    "offense_сodes.count()\n",
    "\n",
    "assert(offense_сodes.count() == 576)\n",
    "\n",
    "offense_сodes.show(100, False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9f6c6542-8f57-45c3-ab84-313abdbd8f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['count DESC NULLS LAST], true\n",
      "+- Aggregate [NAME#1559], [NAME#1559, count(1) AS count#1646L]\n",
      "   +- Filter StartsWith(NAME#1559, ROBBERY)\n",
      "      +- Join Inner, (CODE#1558 = OFFENSE_CODE#246)\n",
      "         :- Relation [INCIDENT_NUMBER#245,OFFENSE_CODE#246,OFFENSE_CODE_GROUP#247,OFFENSE_DESCRIPTION#248,DISTRICT#249,REPORTING_AREA#250,SHOOTING#251,OCCURRED_ON_DATE#252,YEAR#253,MONTH#254,DAY_OF_WEEK#255,HOUR#256,UCR_PART#257,STREET#258,Lat#259,Long#260,Location#261] csv\n",
      "         +- Relation [CODE#1558,NAME#1559] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "NAME: string, count: bigint\n",
      "Sort [count#1646L DESC NULLS LAST], true\n",
      "+- Aggregate [NAME#1559], [NAME#1559, count(1) AS count#1646L]\n",
      "   +- Filter StartsWith(NAME#1559, ROBBERY)\n",
      "      +- Join Inner, (CODE#1558 = OFFENSE_CODE#246)\n",
      "         :- Relation [INCIDENT_NUMBER#245,OFFENSE_CODE#246,OFFENSE_CODE_GROUP#247,OFFENSE_DESCRIPTION#248,DISTRICT#249,REPORTING_AREA#250,SHOOTING#251,OCCURRED_ON_DATE#252,YEAR#253,MONTH#254,DAY_OF_WEEK#255,HOUR#256,UCR_PART#257,STREET#258,Lat#259,Long#260,Location#261] csv\n",
      "         +- Relation [CODE#1558,NAME#1559] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [count#1646L DESC NULLS LAST], true\n",
      "+- Aggregate [NAME#1559], [NAME#1559, count(1) AS count#1646L]\n",
      "   +- Project [NAME#1559]\n",
      "      +- Join Inner, (CODE#1558 = OFFENSE_CODE#246)\n",
      "         :- Project [OFFENSE_CODE#246]\n",
      "         :  +- Filter isnotnull(OFFENSE_CODE#246)\n",
      "         :     +- InMemoryRelation [INCIDENT_NUMBER#245, OFFENSE_CODE#246, OFFENSE_CODE_GROUP#247, OFFENSE_DESCRIPTION#248, DISTRICT#249, REPORTING_AREA#250, SHOOTING#251, OCCURRED_ON_DATE#252, YEAR#253, MONTH#254, DAY_OF_WEEK#255, HOUR#256, UCR_PART#257, STREET#258, Lat#259, Long#260, Location#261], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         :           +- FileScan csv [INCIDENT_NUMBER#245,OFFENSE_CODE#246,OFFENSE_CODE_GROUP#247,OFFENSE_DESCRIPTION#248,DISTRICT#249,REPORTING_AREA#250,SHOOTING#251,OCCURRED_ON_DATE#252,YEAR#253,MONTH#254,DAY_OF_WEEK#255,HOUR#256,UCR_PART#257,STREET#258,Lat#259,Long#260,Location#261] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/D:/private/workspace/spark-cluster/src/main/resources/notebooks/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<INCIDENT_NUMBER:string,OFFENSE_CODE:int,OFFENSE_CODE_GROUP:string,OFFENSE_DESCRIPTION:stri...\n",
      "         +- Filter ((isnotnull(NAME#1559) AND StartsWith(NAME#1559, ROBBERY)) AND isnotnull(CODE#1558))\n",
      "            +- Relation [CODE#1558,NAME#1559] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#1646L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(count#1646L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=566]\n",
      "      +- HashAggregate(keys=[NAME#1559], functions=[count(1)], output=[NAME#1559, count#1646L])\n",
      "         +- Exchange hashpartitioning(NAME#1559, 200), ENSURE_REQUIREMENTS, [plan_id=563]\n",
      "            +- HashAggregate(keys=[NAME#1559], functions=[partial_count(1)], output=[NAME#1559, count#1905L])\n",
      "               +- Project [NAME#1559]\n",
      "                  +- SortMergeJoin [OFFENSE_CODE#246], [CODE#1558], Inner\n",
      "                     :- Sort [OFFENSE_CODE#246 ASC NULLS FIRST], false, 0\n",
      "                     :  +- Exchange hashpartitioning(OFFENSE_CODE#246, 200), ENSURE_REQUIREMENTS, [plan_id=555]\n",
      "                     :     +- Filter isnotnull(OFFENSE_CODE#246)\n",
      "                     :        +- InMemoryTableScan [OFFENSE_CODE#246], [isnotnull(OFFENSE_CODE#246)]\n",
      "                     :              +- InMemoryRelation [INCIDENT_NUMBER#245, OFFENSE_CODE#246, OFFENSE_CODE_GROUP#247, OFFENSE_DESCRIPTION#248, DISTRICT#249, REPORTING_AREA#250, SHOOTING#251, OCCURRED_ON_DATE#252, YEAR#253, MONTH#254, DAY_OF_WEEK#255, HOUR#256, UCR_PART#257, STREET#258, Lat#259, Long#260, Location#261], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                     :                    +- FileScan csv [INCIDENT_NUMBER#245,OFFENSE_CODE#246,OFFENSE_CODE_GROUP#247,OFFENSE_DESCRIPTION#248,DISTRICT#249,REPORTING_AREA#250,SHOOTING#251,OCCURRED_ON_DATE#252,YEAR#253,MONTH#254,DAY_OF_WEEK#255,HOUR#256,UCR_PART#257,STREET#258,Lat#259,Long#260,Location#261] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/D:/private/workspace/spark-cluster/src/main/resources/notebooks/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<INCIDENT_NUMBER:string,OFFENSE_CODE:int,OFFENSE_CODE_GROUP:string,OFFENSE_DESCRIPTION:stri...\n",
      "                     +- Sort [CODE#1558 ASC NULLS FIRST], false, 0\n",
      "                        +- Exchange hashpartitioning(CODE#1558, 200), ENSURE_REQUIREMENTS, [plan_id=556]\n",
      "                           +- Filter ((isnotnull(NAME#1559) AND StartsWith(NAME#1559, ROBBERY)) AND isnotnull(CODE#1558))\n",
      "                              +- FileScan csv [CODE#1558,NAME#1559] Batched: false, DataFilters: [isnotnull(NAME#1559), StartsWith(NAME#1559, ROBBERY), isnotnull(CODE#1558)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/D:/private/workspace/spark-cluster/src/main/resources/notebooks/..., PartitionFilters: [], PushedFilters: [IsNotNull(NAME), StringStartsWith(NAME,ROBBERY), IsNotNull(CODE)], ReadSchema: struct<CODE:int,NAME:string>\n",
      "\n",
      "+--------------------+-----+\n",
      "|                NAME|count|\n",
      "+--------------------+-----+\n",
      "|ROBBERY - FIREARM...|   10|\n",
      "|    ROBBERY - STREET|   10|\n",
      "|     ROBBERY - OTHER|    5|\n",
      "|ROBBERY ATTEMPT -...|    5|\n",
      "|ROBBERY - COMMERCIAL|    4|\n",
      "|ROBBERY - KNIFE -...|    4|\n",
      "|ROBBERY - CAR JAC...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Sort merge join example\n",
    "rob_sort_merge_df = crime_facts.\\\n",
    "    join(offense_сodes, col(\"CODE\") == col(\"OFFENSE_CODE\")).\\\n",
    "    filter(col(\"NAME\").startswith(\"ROBBERY\")).\\\n",
    "    groupBy(col(\"NAME\")).\\\n",
    "    count().\\\n",
    "    orderBy(col(\"count\").desc())\n",
    "\n",
    "\n",
    "rob_sort_merge_df.explain(True)\n",
    "rob_sort_merge_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2dd4b50a-467d-43ff-a2c9-3bebd1ac5380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Sort ['count DESC NULLS LAST], true\n",
      "+- Aggregate [NAME#1559], [NAME#1559, count(1) AS count#2400L]\n",
      "   +- Filter StartsWith(NAME#1559, ROBBERY)\n",
      "      +- Join Inner, (CODE#1558 = OFFENSE_CODE#246)\n",
      "         :- Relation [INCIDENT_NUMBER#245,OFFENSE_CODE#246,OFFENSE_CODE_GROUP#247,OFFENSE_DESCRIPTION#248,DISTRICT#249,REPORTING_AREA#250,SHOOTING#251,OCCURRED_ON_DATE#252,YEAR#253,MONTH#254,DAY_OF_WEEK#255,HOUR#256,UCR_PART#257,STREET#258,Lat#259,Long#260,Location#261] csv\n",
      "         +- ResolvedHint (strategy=broadcast)\n",
      "            +- Relation [CODE#1558,NAME#1559] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "NAME: string, count: bigint\n",
      "Sort [count#2400L DESC NULLS LAST], true\n",
      "+- Aggregate [NAME#1559], [NAME#1559, count(1) AS count#2400L]\n",
      "   +- Filter StartsWith(NAME#1559, ROBBERY)\n",
      "      +- Join Inner, (CODE#1558 = OFFENSE_CODE#246)\n",
      "         :- Relation [INCIDENT_NUMBER#245,OFFENSE_CODE#246,OFFENSE_CODE_GROUP#247,OFFENSE_DESCRIPTION#248,DISTRICT#249,REPORTING_AREA#250,SHOOTING#251,OCCURRED_ON_DATE#252,YEAR#253,MONTH#254,DAY_OF_WEEK#255,HOUR#256,UCR_PART#257,STREET#258,Lat#259,Long#260,Location#261] csv\n",
      "         +- ResolvedHint (strategy=broadcast)\n",
      "            +- Relation [CODE#1558,NAME#1559] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [count#2400L DESC NULLS LAST], true\n",
      "+- Aggregate [NAME#1559], [NAME#1559, count(1) AS count#2400L]\n",
      "   +- Project [NAME#1559]\n",
      "      +- Join Inner, (CODE#1558 = OFFENSE_CODE#246), rightHint=(strategy=broadcast)\n",
      "         :- Project [OFFENSE_CODE#246]\n",
      "         :  +- Filter isnotnull(OFFENSE_CODE#246)\n",
      "         :     +- InMemoryRelation [INCIDENT_NUMBER#245, OFFENSE_CODE#246, OFFENSE_CODE_GROUP#247, OFFENSE_DESCRIPTION#248, DISTRICT#249, REPORTING_AREA#250, SHOOTING#251, OCCURRED_ON_DATE#252, YEAR#253, MONTH#254, DAY_OF_WEEK#255, HOUR#256, UCR_PART#257, STREET#258, Lat#259, Long#260, Location#261], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "         :           +- FileScan csv [INCIDENT_NUMBER#245,OFFENSE_CODE#246,OFFENSE_CODE_GROUP#247,OFFENSE_DESCRIPTION#248,DISTRICT#249,REPORTING_AREA#250,SHOOTING#251,OCCURRED_ON_DATE#252,YEAR#253,MONTH#254,DAY_OF_WEEK#255,HOUR#256,UCR_PART#257,STREET#258,Lat#259,Long#260,Location#261] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/D:/private/workspace/spark-cluster/src/main/resources/notebooks/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<INCIDENT_NUMBER:string,OFFENSE_CODE:int,OFFENSE_CODE_GROUP:string,OFFENSE_DESCRIPTION:stri...\n",
      "         +- Filter ((isnotnull(NAME#1559) AND StartsWith(NAME#1559, ROBBERY)) AND isnotnull(CODE#1558))\n",
      "            +- Relation [CODE#1558,NAME#1559] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "AdaptiveSparkPlan isFinalPlan=false\n",
      "+- Sort [count#2400L DESC NULLS LAST], true, 0\n",
      "   +- Exchange rangepartitioning(count#2400L DESC NULLS LAST, 200), ENSURE_REQUIREMENTS, [plan_id=844]\n",
      "      +- HashAggregate(keys=[NAME#1559], functions=[count(1)], output=[NAME#1559, count#2400L])\n",
      "         +- Exchange hashpartitioning(NAME#1559, 200), ENSURE_REQUIREMENTS, [plan_id=841]\n",
      "            +- HashAggregate(keys=[NAME#1559], functions=[partial_count(1)], output=[NAME#1559, count#2659L])\n",
      "               +- Project [NAME#1559]\n",
      "                  +- BroadcastHashJoin [OFFENSE_CODE#246], [CODE#1558], Inner, BuildRight, false\n",
      "                     :- Filter isnotnull(OFFENSE_CODE#246)\n",
      "                     :  +- InMemoryTableScan [OFFENSE_CODE#246], [isnotnull(OFFENSE_CODE#246)]\n",
      "                     :        +- InMemoryRelation [INCIDENT_NUMBER#245, OFFENSE_CODE#246, OFFENSE_CODE_GROUP#247, OFFENSE_DESCRIPTION#248, DISTRICT#249, REPORTING_AREA#250, SHOOTING#251, OCCURRED_ON_DATE#252, YEAR#253, MONTH#254, DAY_OF_WEEK#255, HOUR#256, UCR_PART#257, STREET#258, Lat#259, Long#260, Location#261], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                     :              +- FileScan csv [INCIDENT_NUMBER#245,OFFENSE_CODE#246,OFFENSE_CODE_GROUP#247,OFFENSE_DESCRIPTION#248,DISTRICT#249,REPORTING_AREA#250,SHOOTING#251,OCCURRED_ON_DATE#252,YEAR#253,MONTH#254,DAY_OF_WEEK#255,HOUR#256,UCR_PART#257,STREET#258,Lat#259,Long#260,Location#261] Batched: false, DataFilters: [], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/D:/private/workspace/spark-cluster/src/main/resources/notebooks/..., PartitionFilters: [], PushedFilters: [], ReadSchema: struct<INCIDENT_NUMBER:string,OFFENSE_CODE:int,OFFENSE_CODE_GROUP:string,OFFENSE_DESCRIPTION:stri...\n",
      "                     +- BroadcastExchange HashedRelationBroadcastMode(List(cast(input[0, int, false] as bigint)),false), [plan_id=836]\n",
      "                        +- Filter ((isnotnull(NAME#1559) AND StartsWith(NAME#1559, ROBBERY)) AND isnotnull(CODE#1558))\n",
      "                           +- FileScan csv [CODE#1558,NAME#1559] Batched: false, DataFilters: [isnotnull(NAME#1559), StartsWith(NAME#1559, ROBBERY), isnotnull(CODE#1558)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/D:/private/workspace/spark-cluster/src/main/resources/notebooks/..., PartitionFilters: [], PushedFilters: [IsNotNull(NAME), StringStartsWith(NAME,ROBBERY), IsNotNull(CODE)], ReadSchema: struct<CODE:int,NAME:string>\n",
      "\n",
      "+--------------------+-----+\n",
      "|                NAME|count|\n",
      "+--------------------+-----+\n",
      "|ROBBERY - FIREARM...|   10|\n",
      "|    ROBBERY - STREET|   10|\n",
      "|     ROBBERY - OTHER|    5|\n",
      "|ROBBERY ATTEMPT -...|    5|\n",
      "|ROBBERY - COMMERCIAL|    4|\n",
      "|ROBBERY - KNIFE -...|    4|\n",
      "|ROBBERY - CAR JAC...|    1|\n",
      "+--------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Broadcast Join Comparing\n",
    "\n",
    "rob_broadcast_df = crime_facts.\\\n",
    "    join(broadcast(offense_сodes), col(\"CODE\") == col(\"OFFENSE_CODE\")).\\\n",
    "    filter(col(\"NAME\").startswith(\"ROBBERY\")).\\\n",
    "    groupBy(col(\"NAME\")).\\\n",
    "    count().\\\n",
    "    orderBy(col(\"count\").desc())\n",
    "\n",
    "rob_broadcast_df.explain(True)\n",
    "rob_broadcast_df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29dd690e-b13b-4833-95b9-9edf679b9066",
   "metadata": {},
   "source": [
    "# Shared variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "89675a59-212f-4d53-b9f3-feb7bc72265e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc = spark.sparkContext\n",
    "accum = sc.accumulator(0)\n",
    "\n",
    "sc.parallelize([1, 2, 3, 4]).foreach(lambda x: accum.add(x))\n",
    "\n",
    "accum.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cdf41522-9e3d-4a2a-a974-52e1c66f2726",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "broadcastVar = sc.broadcast([1, 2, 3])\n",
    "broadcastVar.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f32d9249-ac77-4b53-b53d-e272a12d3128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
